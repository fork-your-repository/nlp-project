{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4473840e-bf12-4a8c-98db-041be45c9e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import nltk\n",
    "# import os\n",
    "# import json\n",
    "# import requests \n",
    "# import time\n",
    "# import re\n",
    "# # import env_miatta as e\n",
    "# # from wrangle import tokenize,clean,nlp_wrangle,intersection_list,extra_clean_column as w\n",
    "# import matplotlib.pyplot as plt\n",
    "# import unicodedata\n",
    "# from bs4 import BeautifulSoup\n",
    "# from typing import Dict, List, Optional, Union, cast\n",
    "# from env_miatta import github_token, github_username\n",
    "# from pprint import pprint\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from nltk.tokenize.toktok import ToktokTokenizer\n",
    "# from nltk.corpus import stopwords\n",
    "# %matplotlib inline\n",
    "# # from time import strftime\n",
    "# #from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import time\n",
    "# import os\n",
    "# import json\n",
    "# import wrangle as w\n",
    "# import model as m\n",
    "\n",
    "# # Data visualization and manipulation\n",
    "# import matplotlib.pyplot as plt\n",
    "# import wordcloud \n",
    "# import seaborn as sns\n",
    "# from pprint import pprint\n",
    "\n",
    "# # Natural language processing and modeling\n",
    "# import nltk.sentiment\n",
    "# import nltk\n",
    "# import re\n",
    "# from scipy.stats import f_oneway, stats\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from nltk.tokenize import ToktokTokenizer\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# # SQL credentials and data acquisition\n",
    "# # import env as e\n",
    "# # import acquire as a\n",
    "# from typing import Dict, List, Optional, Union, cast\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# # GitHub API credentials\n",
    "# # from env import github_token, github_username\n",
    "\n",
    "# import warnings\n",
    "\n",
    "# Import Libraries\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Data Manipulation and Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Custom Modules\n",
    "import wrangle as w\n",
    "import model as m\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "import wordcloud \n",
    "\n",
    "# Natural Language Processing and Modeling\n",
    "import nltk.sentiment\n",
    "import nltk\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.stats import f_oneway, stats\n",
    "from typing import Dict, List, Optional, Union, cast\n",
    "\n",
    "# Web Scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from env_miatta import github_token, github_username as e\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae6ee05-9bb2-4e10-8614-3e2d809d8451",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ACQUIRE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd1618-0173-4f18-9c81-cc718c681502",
   "metadata": {},
   "source": [
    "DATA TYPE SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cd9a68-4ec7-4912-8321-6fa782d9e74f",
   "metadata": {},
   "source": [
    "26 integer data types originally now 3\n",
    "9 object data type originally now 1\n",
    "0 null values\n",
    "no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c3f9e4-c734-49de-8764-ea518ac4ede6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheAlgorithms/Python</td>\n",
       "      <td>Python</td>\n",
       "      <td>&lt;div align=\"center\"&gt;\\n&lt;!-- Title: --&gt;\\n  &lt;a hr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apache/flink</td>\n",
       "      <td>Java</td>\n",
       "      <td># Apache Flink\\n\\nApache Flink is an open sour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>forezp/SpringCloudLearning</td>\n",
       "      <td>Java</td>\n",
       "      <td>&gt;转载请标明出处： \\n&gt; http://blog.csdn.net/forezp/arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>learn-co-students/python-dictionaries-readme-d...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>\\n# Dictionaries \\n\\n### Introduction\\n\\nAfter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angular/angular-phonecat</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># AngularJS Phone Catalog Tutorial Application...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>learn-co-students/javascript-arrays-lab-bootca...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>tastejs/todomvc</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\" d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>learn-co-students/jupyter-notebook-introductio...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>hasura-imad/imad-2016-app</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\" d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>josephmisiti/awesome-machine-learning</td>\n",
       "      <td>Python</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  repo          language  \\\n",
       "0                                 TheAlgorithms/Python            Python   \n",
       "1                                         apache/flink              Java   \n",
       "2                           forezp/SpringCloudLearning              Java   \n",
       "3    learn-co-students/python-dictionaries-readme-d...  Jupyter Notebook   \n",
       "4                             angular/angular-phonecat        JavaScript   \n",
       "..                                                 ...               ...   \n",
       "113  learn-co-students/javascript-arrays-lab-bootca...        JavaScript   \n",
       "114                                    tastejs/todomvc        JavaScript   \n",
       "115  learn-co-students/jupyter-notebook-introductio...  Jupyter Notebook   \n",
       "116                          hasura-imad/imad-2016-app        JavaScript   \n",
       "117              josephmisiti/awesome-machine-learning            Python   \n",
       "\n",
       "                                       readme_contents  \n",
       "0    <div align=\"center\">\\n<!-- Title: -->\\n  <a hr...  \n",
       "1    # Apache Flink\\n\\nApache Flink is an open sour...  \n",
       "2    >转载请标明出处： \\n> http://blog.csdn.net/forezp/arti...  \n",
       "3    \\n# Dictionaries \\n\\n### Introduction\\n\\nAfter...  \n",
       "4    # AngularJS Phone Catalog Tutorial Application...  \n",
       "..                                                 ...  \n",
       "113  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...  \n",
       "114  \\n\\n\\n\\n\\n\\n<!DOCTYPE html>\\n<html lang=\"en\" d...  \n",
       "115  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...  \n",
       "116  \\n\\n\\n\\n\\n\\n<!DOCTYPE html>\\n<html lang=\"en\" d...  \n",
       "117  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...  \n",
       "\n",
       "[118 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aquire data using methods described above.\n",
    "#Read the combined JSON data into a DataFrame\n",
    "words_df = w.pd.read_json('data2.json')\n",
    "words_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e0a3696-05ac-41fa-ad23-56bea38274dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['repo', 'language', 'readme_contents'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset columns\n",
    "words_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "038c155b-5aa1-499c-94fa-9425652830ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JavaScript          31\n",
       "Python              15\n",
       "Java                11\n",
       "HTML                 7\n",
       "C                    6\n",
       "Jupyter Notebook     5\n",
       "Shell                5\n",
       "Ruby                 4\n",
       "C++                  3\n",
       "CSS                  3\n",
       "Go                   3\n",
       "TypeScript           3\n",
       "SCSS                 2\n",
       "PowerShell           1\n",
       "Kotlin               1\n",
       "Bicep                1\n",
       "HCL                  1\n",
       "Vim script           1\n",
       "Objective-C          1\n",
       "Vue                  1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca720ffd-114f-40cf-99ff-87167a8ef133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>repo</th>\n",
       "      <td>TheAlgorithms/Python</td>\n",
       "      <td>apache/flink</td>\n",
       "      <td>forezp/SpringCloudLearning</td>\n",
       "      <td>learn-co-students/python-dictionaries-readme-d...</td>\n",
       "      <td>angular/angular-phonecat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>Python</td>\n",
       "      <td>Java</td>\n",
       "      <td>Java</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>readme_contents</th>\n",
       "      <td>&lt;div align=\"center\"&gt;\\n&lt;!-- Title: --&gt;\\n  &lt;a hr...</td>\n",
       "      <td># Apache Flink\\n\\nApache Flink is an open sour...</td>\n",
       "      <td>&gt;转载请标明出处： \\n&gt; http://blog.csdn.net/forezp/arti...</td>\n",
       "      <td>\\n# Dictionaries \\n\\n### Introduction\\n\\nAfter...</td>\n",
       "      <td># AngularJS Phone Catalog Tutorial Application...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 0  \\\n",
       "repo                                          TheAlgorithms/Python   \n",
       "language                                                    Python   \n",
       "readme_contents  <div align=\"center\">\\n<!-- Title: -->\\n  <a hr...   \n",
       "\n",
       "                                                                 1  \\\n",
       "repo                                                  apache/flink   \n",
       "language                                                      Java   \n",
       "readme_contents  # Apache Flink\\n\\nApache Flink is an open sour...   \n",
       "\n",
       "                                                                 2  \\\n",
       "repo                                    forezp/SpringCloudLearning   \n",
       "language                                                      Java   \n",
       "readme_contents  >转载请标明出处： \\n> http://blog.csdn.net/forezp/arti...   \n",
       "\n",
       "                                                                 3  \\\n",
       "repo             learn-co-students/python-dictionaries-readme-d...   \n",
       "language                                          Jupyter Notebook   \n",
       "readme_contents  \\n# Dictionaries \\n\\n### Introduction\\n\\nAfter...   \n",
       "\n",
       "                                                                 4  \n",
       "repo                                      angular/angular-phonecat  \n",
       "language                                                JavaScript  \n",
       "readme_contents  # AngularJS Phone Catalog Tutorial Application...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To inspect the first few rows of the DataFrame, you can use the head functiotelco.head()\n",
    "words_df.head().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32024e7-3165-4385-b19e-b21de14c8aab",
   "metadata": {},
   "source": [
    "# PREPARE\n",
    "\n",
    "### Data Cleaning:\n",
    "    \n",
    "- Drop unnecessary axis\n",
    "- Rename\n",
    "- Find nulls\n",
    "- Drop nulls\n",
    "- Check preperation\n",
    "- The data set has 4 columns and 1,470 rows\n",
    "- Each row represents individual employee numerical data\n",
    "- Each column is attributes of the employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7387a25-e13a-480e-8264-64f5a3cf0537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for total of duplicates in data set \n",
    "words_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "716d80ad-c32b-4788-a6c2-cfd8208ca203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 118 entries, 0 to 117\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   repo             118 non-null    object\n",
      " 1   language         105 non-null    object\n",
      " 2   readme_contents  118 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# column datatypes and missign values\n",
    "words_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0461087e-a89a-40bf-927f-2bf05cc1b954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>118</td>\n",
       "      <td>105</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>118</td>\n",
       "      <td>20</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>TheAlgorithms/Python</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>&lt;div align=\"center\"&gt;\\n&lt;!-- Title: --&gt;\\n  &lt;a hr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        repo    language  \\\n",
       "count                    118         105   \n",
       "unique                   118          20   \n",
       "top     TheAlgorithms/Python  JavaScript   \n",
       "freq                       1          31   \n",
       "\n",
       "                                          readme_contents  \n",
       "count                                                 118  \n",
       "unique                                                118  \n",
       "top     <div align=\"center\">\\n<!-- Title: -->\\n  <a hr...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observed numerical values\n",
    "words_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c05782dd-6e11-47d1-b0ca-96c21c7a4967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6500e499-c504-4067-ac84-b2af1b57a9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      repo  language  readme_contents\n",
       "0    False     False            False\n",
       "1    False     False            False\n",
       "2    False     False            False\n",
       "3    False     False            False\n",
       "4    False     False            False\n",
       "..     ...       ...              ...\n",
       "113  False     False            False\n",
       "114  False     False            False\n",
       "115  False     False            False\n",
       "116  False     False            False\n",
       "117  False     False            False\n",
       "\n",
       "[118 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = words_df.isnull()\n",
    "missing_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd16933e-56b0-43c6-bdde-ac131e3389fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repo                0\n",
       "language           13\n",
       "readme_contents     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c77392e-0ca8-47c0-a015-a38a74cc04aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheAlgorithms/Python</td>\n",
       "      <td>Python</td>\n",
       "      <td>&lt;div align=\"center\"&gt;\\n&lt;!-- Title: --&gt;\\n  &lt;a hr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apache/flink</td>\n",
       "      <td>Java</td>\n",
       "      <td># Apache Flink\\n\\nApache Flink is an open sour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>forezp/SpringCloudLearning</td>\n",
       "      <td>Java</td>\n",
       "      <td>&gt;转载请标明出处： \\n&gt; http://blog.csdn.net/forezp/arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>learn-co-students/python-dictionaries-readme-d...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>\\n# Dictionaries \\n\\n### Introduction\\n\\nAfter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angular/angular-phonecat</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># AngularJS Phone Catalog Tutorial Application...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>learn-co-students/javascript-arrays-lab-bootca...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>tastejs/todomvc</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\" d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>learn-co-students/jupyter-notebook-introductio...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>hasura-imad/imad-2016-app</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\" d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>josephmisiti/awesome-machine-learning</td>\n",
       "      <td>Python</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  repo          language  \\\n",
       "0                                 TheAlgorithms/Python            Python   \n",
       "1                                         apache/flink              Java   \n",
       "2                           forezp/SpringCloudLearning              Java   \n",
       "3    learn-co-students/python-dictionaries-readme-d...  Jupyter Notebook   \n",
       "4                             angular/angular-phonecat        JavaScript   \n",
       "..                                                 ...               ...   \n",
       "113  learn-co-students/javascript-arrays-lab-bootca...        JavaScript   \n",
       "114                                    tastejs/todomvc        JavaScript   \n",
       "115  learn-co-students/jupyter-notebook-introductio...  Jupyter Notebook   \n",
       "116                          hasura-imad/imad-2016-app        JavaScript   \n",
       "117              josephmisiti/awesome-machine-learning            Python   \n",
       "\n",
       "                                       readme_contents  \n",
       "0    <div align=\"center\">\\n<!-- Title: -->\\n  <a hr...  \n",
       "1    # Apache Flink\\n\\nApache Flink is an open sour...  \n",
       "2    >转载请标明出处： \\n> http://blog.csdn.net/forezp/arti...  \n",
       "3    \\n# Dictionaries \\n\\n### Introduction\\n\\nAfter...  \n",
       "4    # AngularJS Phone Catalog Tutorial Application...  \n",
       "..                                                 ...  \n",
       "113  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...  \n",
       "114  \\n\\n\\n\\n\\n\\n<!DOCTYPE html>\\n<html lang=\"en\" d...  \n",
       "115  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...  \n",
       "116  \\n\\n\\n\\n\\n\\n<!DOCTYPE html>\\n<html lang=\"en\" d...  \n",
       "117  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...  \n",
       "\n",
       "[105 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with any missing values\n",
    "words_df_dropped = words_df.dropna()\n",
    "words_df_dropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7daa5ab7-035c-436b-a3af-a61f2efd0da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vivienzou1/DL-Notes-for-interview</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jtleek/datasharing</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>freefq/free</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>996icu/996.ICU</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>luchihoratiu/debug-via-ssh</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>mqyqingfeng/Blog</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>xitu/gold-miner</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>xingshaocheng/architect-awesome</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>dcxy/learngit</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\" d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>bloominstituteoftechnology/module-challenge-in...</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>othneildrew/Best-README-Template</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>bloominstituteoftechnology/team-builder</td>\n",
       "      <td>None</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>amjuarez/bytecoin</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\" d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 repo language  \\\n",
       "9                   vivienzou1/DL-Notes-for-interview     None   \n",
       "11                                 jtleek/datasharing     None   \n",
       "13                                        freefq/free     None   \n",
       "17                                     996icu/996.ICU     None   \n",
       "26                         luchihoratiu/debug-via-ssh     None   \n",
       "29                                   mqyqingfeng/Blog     None   \n",
       "40                                    xitu/gold-miner     None   \n",
       "41                    xingshaocheng/architect-awesome     None   \n",
       "54                                      dcxy/learngit     None   \n",
       "68  bloominstituteoftechnology/module-challenge-in...     None   \n",
       "73                   othneildrew/Best-README-Template     None   \n",
       "84            bloominstituteoftechnology/team-builder     None   \n",
       "90                                  amjuarez/bytecoin     None   \n",
       "\n",
       "                                      readme_contents  \n",
       "9   {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...  \n",
       "11  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...  \n",
       "13  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...  \n",
       "17  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...  \n",
       "26  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...  \n",
       "29  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...  \n",
       "40  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...  \n",
       "41  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...  \n",
       "54  \\n\\n\\n\\n\\n\\n<!DOCTYPE html>\\n<html lang=\"en\" d...  \n",
       "68  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...  \n",
       "73  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...  \n",
       "84  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...  \n",
       "90  \\n\\n\\n\\n\\n\\n<!DOCTYPE html>\\n<html lang=\"en\" d...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_missing_language = words_df[words_df['language'].isnull()]\n",
    "\n",
    "# Change data types of the isolated rows to 'object'\n",
    "rows_with_missing_language = rows_with_missing_language.astype({'language': 'object'})\n",
    "\n",
    "# Display the modified isolated rows\n",
    "rows_with_missing_language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ba49866-627f-42c2-8fc5-f6159846d8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 118 entries, 0 to 117\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   repo             118 non-null    object\n",
      " 1   language         105 non-null    object\n",
      " 2   readme_contents  118 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# column datatypes \n",
    "words_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fd15ee8-cb7d-4e46-9316-c26734c6da72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null values in the 'language' column with \"Other\"\n",
    "words_df['language'].fillna(\"Other\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ffcdcce-e703-4ad0-bf69-b92a289a0d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 118 entries, 0 to 117\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   repo             118 non-null    object\n",
      " 1   language         118 non-null    object\n",
      " 2   readme_contents  118 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#column datatypes \n",
    "words_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20f92e85-9c78-4543-a680-9d5c9e858344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>repo</th>\n",
       "      <td>TheAlgorithms/Python</td>\n",
       "      <td>apache/flink</td>\n",
       "      <td>forezp/SpringCloudLearning</td>\n",
       "      <td>learn-co-students/python-dictionaries-readme-d...</td>\n",
       "      <td>angular/angular-phonecat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>Python</td>\n",
       "      <td>Java</td>\n",
       "      <td>Java</td>\n",
       "      <td>Other</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>readme_contents</th>\n",
       "      <td>&lt;div align=\"center\"&gt;\\n&lt;!-- Title: --&gt;\\n  &lt;a hr...</td>\n",
       "      <td># Apache Flink\\n\\nApache Flink is an open sour...</td>\n",
       "      <td>&gt;转载请标明出处： \\n&gt; http://blog.csdn.net/forezp/arti...</td>\n",
       "      <td>\\n# Dictionaries \\n\\n### Introduction\\n\\nAfter...</td>\n",
       "      <td># AngularJS Phone Catalog Tutorial Application...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean_contents</th>\n",
       "      <td>gn center title href    thelrithms  src  rw u...</td>\n",
       "      <td>che fnk che fnk oen source strem rocessing frm...</td>\n",
       "      <td>blog csdn net forez rticle detil   blog csdn ...</td>\n",
       "      <td>dictionry introduction introducing working st ...</td>\n",
       "      <td>ngrjs hone ctlog tutoril ction overview ction ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message_length</th>\n",
       "      <td>1585</td>\n",
       "      <td>2722</td>\n",
       "      <td>4370</td>\n",
       "      <td>5385</td>\n",
       "      <td>6259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>257</td>\n",
       "      <td>454</td>\n",
       "      <td>617</td>\n",
       "      <td>828</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra_clean_contents</th>\n",
       "      <td>b better blob blue build center code contribut...</td>\n",
       "      <td>bug build building built che check clone code ...</td>\n",
       "      <td>boot boots bus center cloud cor discovery f fe...</td>\n",
       "      <td>bee beginning bit built ce continue correct co...</td>\n",
       "      <td>b best binding bine building cent check checko...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      0  \\\n",
       "repo                                               TheAlgorithms/Python   \n",
       "language                                                         Python   \n",
       "readme_contents       <div align=\"center\">\\n<!-- Title: -->\\n  <a hr...   \n",
       "clean_contents         gn center title href    thelrithms  src  rw u...   \n",
       "message_length                                                     1585   \n",
       "word_count                                                          257   \n",
       "extra_clean_contents  b better blob blue build center code contribut...   \n",
       "\n",
       "                                                                      1  \\\n",
       "repo                                                       apache/flink   \n",
       "language                                                           Java   \n",
       "readme_contents       # Apache Flink\\n\\nApache Flink is an open sour...   \n",
       "clean_contents        che fnk che fnk oen source strem rocessing frm...   \n",
       "message_length                                                     2722   \n",
       "word_count                                                          454   \n",
       "extra_clean_contents  bug build building built che check clone code ...   \n",
       "\n",
       "                                                                      2  \\\n",
       "repo                                         forezp/SpringCloudLearning   \n",
       "language                                                           Java   \n",
       "readme_contents       >转载请标明出处： \\n> http://blog.csdn.net/forezp/arti...   \n",
       "clean_contents         blog csdn net forez rticle detil   blog csdn ...   \n",
       "message_length                                                     4370   \n",
       "word_count                                                          617   \n",
       "extra_clean_contents  boot boots bus center cloud cor discovery f fe...   \n",
       "\n",
       "                                                                      3  \\\n",
       "repo                  learn-co-students/python-dictionaries-readme-d...   \n",
       "language                                                          Other   \n",
       "readme_contents       \\n# Dictionaries \\n\\n### Introduction\\n\\nAfter...   \n",
       "clean_contents        dictionry introduction introducing working st ...   \n",
       "message_length                                                     5385   \n",
       "word_count                                                          828   \n",
       "extra_clean_contents  bee beginning bit built ce continue correct co...   \n",
       "\n",
       "                                                                      4  \n",
       "repo                                           angular/angular-phonecat  \n",
       "language                                                     JavaScript  \n",
       "readme_contents       # AngularJS Phone Catalog Tutorial Application...  \n",
       "clean_contents        ngrjs hone ctlog tutoril ction overview ction ...  \n",
       "message_length                                                     6259  \n",
       "word_count                                                         1028  \n",
       "extra_clean_contents  b best binding bine building cent check checko...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df = w.nlp_wrangle()\n",
    "intersect =w.intersection_list()\n",
    "words_df =w.extra_clean_column(words_df,intersect)\n",
    "words_df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcc3ede-66f1-4be4-b095-9ab6eb05c1df",
   "metadata": {},
   "source": [
    "### TRAIN SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94ff13c0-3653-4221-a66d-e0260421c593",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Split the dataset into training, validation, and test sets based on the 'language' variable\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train, validate, test \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlanguage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Display the first few rows of the training dataset\u001b[39;00m\n\u001b[1;32m      5\u001b[0m train\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/codeup-data-science/nlp-project/model.py:15\u001b[0m, in \u001b[0;36msplit_data\u001b[0;34m(df, variable)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mSplits the data into train, validate, and test DataFrames.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03mtrain, validate, test DataFrames.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Split data into train, validate, and test\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m train_validate, test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(df, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.20\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mdf[variable])\n\u001b[1;32m     16\u001b[0m train, validate \u001b[38;5;241m=\u001b[39m train_test_split(train_validate, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mtrain_validate[variable])\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train, validate, test\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training, validation, and test sets based on the 'language' variable\n",
    "train, validate, test = m.split_data(words_df, 'language')\n",
    "\n",
    "# Display the first few rows of the training dataset\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae565542-152f-4927-9925-5843c6cf9682",
   "metadata": {},
   "source": [
    "# EXPLORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f475e69-1e84-4a95-b672-e040d3a85747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the graph you havw=e in wrngle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f164d4f-cf49-4423-b2ba-61dbae6a4c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual of dataset after cleaning and split \n",
    "\n",
    "words_df.hist(figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd179ec-a6f9-4c14-b7b3-0566b9606872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the create_bar_chart function to visualize the distribution of categories\n",
    "w.create_bar_chart(words_df, 'language', 'Distribution of Categories')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0673b814-5204-4a21-9755-6e25ff71180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract words from READMEs written in Python language and clean them\n",
    "python_words = clean(' '.join(train[train.language==\"Python\"]['extra_clean_contents']))\n",
    "\n",
    "# Extract words from READMEs written in Java language and clean them\n",
    "java_words = clean(' '.join(train[train.language==\"Java\"]['extra_clean_contents']))\n",
    "\n",
    "# Extract words from READMEs written in JavaScript language and clean them\n",
    "script_words = clean(' '.join(train[train.language==\"JavaScript\"]['extra_clean_contents']))\n",
    "\n",
    "# Extract words from READMEs written in HTML language and clean them\n",
    "html_words = clean(' '.join(train[train.language==\"HTML\"]['extra_clean_contents']))\n",
    "\n",
    "# Extract words from READMEs written in TypeScript language and clean them\n",
    "type_words = clean(' '.join(train[train.language==\"TypeScript\"]['extra_clean_contents']))\n",
    "\n",
    "# Extract words from READMEs not categorized into specific languages and clean them\n",
    "other_words = clean(' '.join(train[train.language==\"Other\"]['extra_clean_contents']))\n",
    "\n",
    "# Extract words from READMEs in the test set and clean them\n",
    "all_words = clean(' '.join(test['extra_clean_contents']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a283ebf-e36f-4923-b8dd-dce5e438515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the word frequency for Python language\n",
    "python_freq = pd.Series(python_words).value_counts()\n",
    "\n",
    "# Calculate the word frequency for Java language\n",
    "java_freq = pd.Series(java_words).value_counts()\n",
    "\n",
    "# Calculate the word frequency for JavaScript language\n",
    "script_freq = pd.Series(script_words).value_counts()\n",
    "\n",
    "# Calculate the word frequency for HTML language\n",
    "html_freq = pd.Series(html_words).value_counts()\n",
    "\n",
    "# Calculate the word frequency for TypeScript language\n",
    "type_freq = pd.Series(type_words).value_counts()\n",
    "\n",
    "# Calculate the word frequency for all languages combined\n",
    "all_freq = pd.Series(all_words).value_counts()\n",
    "\n",
    "# Calculate the word frequency for words not categorized in specific languages\n",
    "other_freq = pd.Series(other_words).value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2609ff-897e-44a0-b482-90dee8e27bc3",
   "metadata": {},
   "source": [
    "**JAVASCRIPT**          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d29516-246f-4dd1-ac7d-c2a0f82e04c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top 10 most common words for the 'script' category in descending order\n",
    "word_counts.script.sort_values(ascending=False).head(10)\n",
    "# Top 3 words: id, desk, rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a447e1b-8a91-4546-9b12-8ac1a3e86735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a word cloud image using the 'script_words' list, with a white background\n",
    "img = WordCloud(background_color='white').generate(' '.join(script_words))\n",
    "\n",
    "# Display the word cloud image without axis\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Most Common JavaScript Words')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864cde2e-d85d-4874-a0af-4dcb2618bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a word cloud image using the 'script_words' list, with a black background\n",
    "colors = [\"red\", \"yellow\", \"orange\", \"pink\"]\n",
    "img = WordCloud(background_color='black', colormap=colors).generate(' '.join(script_words))\n",
    "\n",
    "# Display the word cloud image without axis\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Most Common JavaScript Words')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9da2f9-aaed-4c0c-9247-9a9ef8b23811",
   "metadata": {},
   "source": [
    "**PYTHON**            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28782d89-aa0d-4747-9a46-056bbc7bddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_python_words = set(python_words)\n",
    "set_python_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b85a635-6509-454d-b83b-4d1769d6850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set_python_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d882ace5-2789-4f46-9532-de19b5b2ae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5853f897-e3bc-4e69-8d7b-ea1328a73a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JavaScript, Other have the most words\n",
    "len(python_words), len(java_words), len(script_words), len(html_words), len(type_words), len(other_words), len(all_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c21baeb-d5de-4ee4-ab27-b90df25be71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the top 10 most frequent words in the 'python' category\n",
    "word_counts.python.sort_values(ascending=False).head(10)\n",
    "\n",
    "# Top 3 words: user, desk, rel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca64fa-da2b-475c-b48c-b47847e52a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a word cloud visualization for the most common Python words\n",
    "img = WordCloud(background_color='white').generate(' '.join(python_words))\n",
    "\n",
    "# Display the generated image\n",
    "plt.imshow(img)\n",
    "\n",
    "# Turn off axis display\n",
    "plt.axis('off')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Most Common Python Words')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0ce127-a65d-4352-880c-353423822e7b",
   "metadata": {},
   "source": [
    "**JAVA**                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e912fc65-e467-42cb-a689-60f38286107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top 10 most common words in the Java programming language\n",
    "word_counts.java.sort_values(ascending=False).head(10)\n",
    "\n",
    "#Top 3 words: setting, id, version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e2b76b-3488-4bb7-90f7-85abeed0f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display a word cloud visualization for the most common Java words\n",
    "img = WordCloud(background_color='white').generate(' '.join(java_words))\n",
    "\n",
    "# Display the word cloud image without axis\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "\n",
    "# Set the title of the word cloud plot\n",
    "plt.title('Most Common Java Words')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670cdf2b-1d18-4131-8c2e-c8370ca5d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a word cloud image using the 'script_words' list, with a black background\n",
    "colors = [\"red\", \"yellow\", \"orange\", \"pink\"]\n",
    "img = WordCloud(background_color='black', colormap=colors).generate(' '.join(all_words))\n",
    "\n",
    "# Display the word cloud image without axis\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('All Most Common Words')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c60847c-b040-4620-bcc4-07e3a6d8d89b",
   "metadata": {},
   "source": [
    "**HTML**                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e6df33-2768-4aa4-a268-1ce40a88d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top 10 most common words in the HTML programming language\n",
    "word_counts.html.sort_values(ascending=False).head(10)\n",
    "\n",
    "# Top 3 words: body, id, reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56647442-5d45-4203-b673-70327ff2aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a word cloud image using the 'HTML' list, with a black background\n",
    "colors = [\"red\", \"yellow\", \"orange\", \"pink\"]\n",
    "img = WordCloud(background_color='black', colormap=colors).generate(' '.join(all_words))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884b7853-c7bf-425b-9c70-cb7ce601958e",
   "metadata": {},
   "source": [
    "**TYPESCRIPT**           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7107171-547c-4cc4-8c74-d581e0e97077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top 10 most common words in the TypeScript programming language\n",
    "word_counts.type.sort_values(ascending=False).head(10)\n",
    "\n",
    "# Top 3 words: mount, round, overview.However, there is a small sample size here, so this is likely not representative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51965a7b-bc24-4df8-a015-6a26a4a3dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a word cloud image using the 'script_words' list, with a black background\n",
    "colors = [\"red\", \"yellow\", \"orange\", \"pink\"]\n",
    "img = WordCloud(background_color='black', colormap=colors).generate(' '.join(type_words))\n",
    "\n",
    "# Display the word cloud image without axis\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Most Common TypeScript Words')\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1a871a-f221-4dd2-961e-f1413a568ef3",
   "metadata": {},
   "source": [
    "**OTHER**       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40292d3-9315-461c-98d5-852223217074",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts.other.sort_values(ascending=False).head(10)\n",
    "\n",
    "# Top 3 words: height, setting, reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5a0b23-c438-4174-be0a-24d4fb147fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a word cloud image using the 'other' list, with a black background\n",
    "colors = [\"red\", \"yellow\", \"orange\", \"pink\"]\n",
    "img = WordCloud(background_color='black', colormap=colors).generate(' '.join(other_words))\n",
    "\n",
    "# Display the word cloud image without axis\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Most Common Other Programming Language Words')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f16e13a-ca5f-44ea-b0db-687e37815d95",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ALL LANGUAGE OBSERVED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e313ea-b05c-448a-ae4f-0d66b2d6aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate frequency DataFrames for each language and the overall frequency axis=1 concatenates the DataFrames horizontally (side by side)\n",
    "\n",
    "# Fill missing values (NaNs) with 0 and convert all values to integers\n",
    "word_counts = pd.concat([python_freq, java_freq, script_freq, html_freq, type_freq, other_freq, all_freq], axis=1).fillna(0).astype(int)\n",
    "\n",
    "# Rename the column names to match the respective programming languages and an 'all' category\n",
    "word_counts.columns = ['python', 'java', 'script', 'html', 'type', 'other', 'all']\n",
    "\n",
    "# Display the first few rows of the 'word_counts' DataFrame\n",
    "word_counts.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faef4764-064e-47aa-9339-b66246e81f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top 10 most common words on ALL programming languages\n",
    "word_counts['all'].sort_values(ascending=False).head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926822fb-b50e-439a-8f54-0eb0977dd1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a word cloud image using the 'script_words' list, with a black background\n",
    "colors = [\"red\", \"yellow\", \"orange\", \"pink\"]\n",
    "img = WordCloud(background_color='black', colormap=colors).generate(' '.join(all_words))\n",
    "\n",
    "# Display the word cloud image without axis\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('All Most Common Words')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9868f0-495a-43b9-9d33-e7e8955b9728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a49bc1-9b33-48fb-9b2e-2e46072c1ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3f613f8-5704-4a4a-ad9d-f2aef0e3ab8d",
   "metadata": {},
   "source": [
    "### Question 1: Are there any notable variations in the frequency of words between README files written in different programming languages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aee488-c497-4d39-b081-fae35906a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame 'word_counts' in descending order based on the 'all' column. This will arrange the words in the DataFrame by their frequency in descending order\n",
    "\n",
    "word_counts.sort_values('all', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874062e3-81da-4276-8dc7-b52f86b7e7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default figure size for matplotlib plots to (13, 7)\n",
    "plt.rc('figure', figsize=(13, 7))\n",
    "\n",
    "# Apply the 'seaborn-darkgrid' style to matplotlib plots.This style provides a dark background with gridlines, enhancing visualization\n",
    "plt.style.use('seaborn-darkgrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ead79-bece-4f62-8dd2-2e9032f1333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the 'word_counts' DataFrame based on the 'all' column in descending order,then select the top 20 rows and columns 'python', 'script', and 'other'.Finally, create a horizontal bar plot to visualize the top 20 words for each language\n",
    "word_counts.sort_values('all', ascending=False)[['python', 'script', 'other']].head(20).plot.barh()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f586121b-5229-4afa-b169-fca924be2b5d",
   "metadata": {},
   "source": [
    "**The words in each language seem to vary in the same way. This may be an artifact of cleaning the words by only accepting dictionary words.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cf329d-1aac-4d55-b954-6efa08a25ab4",
   "metadata": {},
   "source": [
    "### Question 2: Does the presence of specific libraries in the README file correspond with the programming language used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14f1671-c6cd-4f37-ba68-9c99e61c8208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_word_frequency(train):\n",
    "    \"\"\"\n",
    "    Analyzes word frequency in specific libraries/tools across different programming languages.\n",
    "\n",
    "    Args:\n",
    "    train (pandas.DataFrame): DataFrame containing the training data.\n",
    "\n",
    "    Returns:\n",
    "    word_counts (pandas.DataFrame): DataFrame with word counts for each programming language, overall, and specific libraries/tools.\n",
    "\n",
    "    \"\"\"\n",
    "    # Get words for each programming language and overall\n",
    "    categories = ['JavaScript', 'Python', 'Java', 'HTML','TypeScript','Other']\n",
    "    all_words = clean(' '.join(train['clean_contents']))\n",
    "    category_words = [clean(' '.join(train[train.language == category]['clean_contents'])) for category in categories]\n",
    "\n",
    "    # Get word frequency for each category\n",
    "    category_words_freq = [pd.Series(words).value_counts() for words in category_words]\n",
    "    \n",
    "    # Filter words by specific library\n",
    "    libraries_to_check = ['flexbox', 'chatgpt', 'cli', 'stackblitz', 'angular', 'apm', 'opencv', 'zendesk', 'bootstrap', 'jquery', 'virtualbox', 'vagrant', 'nbsp', 'machinelearning', 'apache', 'dubbo', 'alibaba', 'pandas', 'numpy']\n",
    "    filtered_list = [word for word in all_words if word in libraries_to_check]\n",
    "    filtered_list_freq = pd.Series(filtered_list).value_counts()\n",
    "\n",
    "    # Create DataFrame with word counts\n",
    "    word_counts = pd.concat(category_words_freq + [pd.Series(filtered_list_freq)], axis=1).fillna(0).astype(int)\n",
    "\n",
    "    # Rename columns\n",
    "    word_counts.columns = categories + ['All', 'Tools_Frameworks']\n",
    "\n",
    "    # Visualize\n",
    "    word_counts.sort_values('Tools_Frameworks', ascending=False)[categories].head(14).plot.barh()\n",
    "    plt.xlabel('Word Count')\n",
    "    plt.title('Word Count by Language and Specific Library')\n",
    "    plt.show()\n",
    "\n",
    "    return word_counts\n",
    "\n",
    "# Call the function\n",
    "word_counts_result = analyze_word_frequency(train)\n",
    "word_counts_result.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1821e9ef-9f54-4483-805b-f841713aa258",
   "metadata": {},
   "source": [
    "### Question 3: What are the most frequently used words throughout the dataset and for each language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b8287-dc39-485e-979e-9cd4b845de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the 'all' column from the 'word_counts' DataFrameThen, sort the values in descending order to get the most frequent words first\n",
    "\n",
    "# Use .head(10) to extract the top 10 most frequent words\n",
    "most_common_words = word_counts['all'].sort_values(ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d0ae5-dbe1-43bf-9752-4106c5c25b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a WordCloud image from the joined 'all_words' list\n",
    "\n",
    "# The WordCloud will have a white background\n",
    "img = WordCloud(background_color='white').generate(' '.join(all_words))\n",
    "\n",
    "# Display the WordCloud image using plt.imshow()\n",
    "plt.imshow(img)\n",
    "\n",
    "# Turn off the axis to remove axes labels and ticks\n",
    "plt.axis('off')\n",
    "\n",
    "# Set the title for the WordCloud visualization\n",
    "plt.title('All Most Common Words')\n",
    "\n",
    "# Display the WordCloud visualization\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493f5c39-4450-4085-9a70-9ea6a657947f",
   "metadata": {},
   "source": [
    "Top 3 words: height, must, reference\n",
    "\n",
    "Words that seem to be common among coding languages: title, desk, height, blob# Concatenate frequency DataFrames for each language and the overall frequency axis=1 concatenates the DataFrames horizontally (side by side)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e27331f-6dc6-4b0c-92a0-49fbdc482cc4",
   "metadata": {},
   "source": [
    "### Question 4: What are the least frequently used words throughout the dataset and for each language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4bf1af-5fd2-42d4-a4c4-2643ffa2e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_used_words_per_language(train):\n",
    "    \"\"\"\n",
    "    Determines the least used words and their corresponding language across different programming languages.\n",
    "\n",
    "    Args:\n",
    "    train (pandas.DataFrame): DataFrame containing the training data.\n",
    "\n",
    "    Returns:\n",
    "    least_used_words_per_column (pandas.Series): Series containing the least used words and their corresponding language.\n",
    "\n",
    "    \"\"\"\n",
    "    # Gather words for each programming language and overall\n",
    "    categories = ['JavaScript', 'Python', 'Java', 'HTML','TypeScript','Other']\n",
    "    all_words = clean(' '.join(train['clean_contents']))\n",
    "    category_words = [clean(' '.join(train[train.language == category]['clean_contents'])) for category in categories]\n",
    "\n",
    "    # Calculate word frequency for each category\n",
    "    category_words_freq = [pd.Series(words).value_counts() for words in category_words]\n",
    "\n",
    "    # Combine word frequencies for analysis\n",
    "    word_counts = pd.concat(category_words_freq, axis=1).fillna(0).astype(int)\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    word_counts.columns = categories\n",
    "\n",
    "    # Sort columns based on overall word count\n",
    "    word_counts_sorted = word_counts.sort_values('All', ascending=False)\n",
    "\n",
    "    # Calculate the total count of words across all columns\n",
    "    word_counts_sorted['Total'] = word_counts_sorted.sum(axis=1)\n",
    "\n",
    "    # Extract the least used words per programming language\n",
    "    least_used_words_per_column = word_counts_sorted.idxmin()\n",
    "\n",
    "    return least_used_words_per_column\n",
    "\n",
    "# Call the function and display the result\n",
    "result_least_used_words = least_used_words_per_language(train)\n",
    "print(result_least_used_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abec1a95-8002-4567-85b7-07a884bbb50c",
   "metadata": {},
   "source": [
    "### Feature will be tested and modeled against Attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa9d768-0bf2-4680-842a-238f610d6a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd29af64-eab8-437c-91a7-f66c2277dfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_classification_matrix(X_bow, y_train, X_validate_bow, y_validate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aba018-970c-4190-a7d3-ac203487376c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea772001-7e61-46ab-ac77-3b018417700b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922523f2-547c-4196-874f-e6ed5dc59092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # Visualize the data\n",
    "\n",
    "# # Example: Histogram of 'Age'\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.histplot(selected_train['Age'], kde=True)\n",
    "# plt.title('Age Distribution')\n",
    "# plt.xlabel('Age')\n",
    "# plt.ylabel('Count')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e15f04f-ddb5-4aa7-88d7-aaf4d62e821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Explore the Age vs Attrition\n",
    "\n",
    "# # Example: Bar plot of 'Age' vs. 'Attrition'\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.countplot(data=selected_train, x='Age', hue='Yes_Attrition')\n",
    "# plt.title('Does Age have a relationship with employee Attrition?')\n",
    "# plt.xlabel('Age')\n",
    "# plt.ylabel('Count')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1990a0-7939-4e02-9710-1258063a9a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example: Bar plot of 'Education' vs. 'Attrition''\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.countplot(data=selected_train, x='Education', hue='Yes_Attrition')\n",
    "# plt.title('Does Education have a relationship with employee Attrition?')\n",
    "# plt.xlabel('Education')\n",
    "# plt.ylabel('Count')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a666f-eb57-4c1e-95e5-c4a2d05978be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.kdeplot(data=selected_df, x='Tenure', hue='Yes_Attrition', fill=True)\n",
    "# plt.title('Does Tenure have a relationship with employee Attrition?')\n",
    "# plt.xlabel('Tenure')\n",
    "# plt.ylabel('Density')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dec7a0e-fbc2-4fe0-a4d7-e96dba4ee7c8",
   "metadata": {},
   "source": [
    "# STATISTICAL TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5effdf8a-51d0-4485-84e4-79363e293135",
   "metadata": {},
   "source": [
    "### Question 1: Are there any notable variations in the frequency of words between README files written in different programming languages?\n",
    "\n",
    "- **$H_{0}$** There is no significant variation in the frequency of words between README files written in different programming languages.\n",
    "- **$H_{a}$** There are significant variations in the frequency of words between README files written in different programming languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e99611d-b859-4f05-b4e6-91a6d416682c",
   "metadata": {},
   "source": [
    "### Question 2: Does the presence of specific libraries in the README file correspond with the programming language used?\n",
    "\n",
    "- **$H_{0}$** The presence of specific libraries in the README file does not correspond with the programming language used.\n",
    "- **$H_{a}$** The presence of specific libraries in the README file corresponds with the programming language used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709b2777-d0d6-49a6-a67d-2ccf81382719",
   "metadata": {},
   "source": [
    "### Question 3: What are the most frequently used words throughout the dataset and for each language?\n",
    "\n",
    "- **$H_{0}$** The frequency distribution of words is similar throughout the dataset and across different programming languages.\n",
    "- **$H_{a}$** The frequency distribution of words is significantly different throughout the dataset and across different programming languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e785608-150b-4861-9b2f-a8c5cf31f6d5",
   "metadata": {},
   "source": [
    "### Question 4: What are the least frequently used words throughout the dataset and for each language?\n",
    "- **$H_{0}$** The least frequent words have consistent usage patterns throughout the dataset and across different programming languages.\n",
    "- **$H_{a}$** The least frequent words have varying usage patterns throughout the dataset and across different programming languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4beda25-f269-45b1-984c-bbf5aae2811d",
   "metadata": {},
   "source": [
    "# STATISTICAL FINDINGS\n",
    "- ge Hypothesis - We reject the Null Hypothesis, Age is dependent on employee Attrition.\n",
    "- Education Hypothesis We reject the Null Hypothesis, education is dependent on on employee Attrition.\n",
    "- Tenure Hypothesis - We fail to reject the Null Hypothesis, Tenure is independent of employee Attrition.\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c47203d-9615-4cd7-a69a-f3db9502cecc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SPLITTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df4c1c-caa4-44a3-8065-0b3d4b349e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = m.split_data(words_df, 'language')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fcf3d1-00c4-4aa6-b5a1-3e5e34e9b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ca7f9c-fc55-4a9b-810b-9d436bed30ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data in to X and Y for all datasets with Yes_Attrition and those without \n",
    "\n",
    "X_bow, X_validate_bow, X_test_bow, y_train, y_validate, y_test, feature_names = prepare_for_modeling(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e1c9bb-b15d-4152-886e-7244ce0b2640",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = decision_tree(X_bow, X_validate_bow, y_train, y_validate)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f871386e-c5d5-47ce-9761-da55703b84bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_y_train.head()\n",
    "selected_y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d816aedb-3f80-4bb9-8e5f-57a6c94fc43a",
   "metadata": {},
   "source": [
    "### EVALUATE BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965bb878-2217-4724-9b0b-323042c0d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline =(selected_y_train==0).mean()\n",
    "# print(f'The baseline accuracy is: {baseline:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9f9f64-982f-47ef-9cae-77bbe29dc4ac",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68be3c3e-663a-462d-9cfc-35882f526f55",
   "metadata": {},
   "source": [
    "### DECISION TREE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373e54c5-abe1-4907-8743-7aedec20bc6d",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8b54ec-069d-411d-9ec2-a279b5b319b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48101259-5199-4661-a895-bf357e9097a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def k_nearest(X_bow, y_train, X_validate_bow, y_validate):\n",
    "    \"\"\"\n",
    "    Trains and evaluates KNN models for different values of k and plots the results.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_bow: array-like, shape (n_samples, n_features)\n",
    "        Bag-of-words representations of training samples.\n",
    "    y_train: array-like, shape (n_samples,)\n",
    "        Target values for the training samples.\n",
    "    X_validate_bow: array-like, shape (n_samples, n_features)\n",
    "        Bag-of-words representations of validation samples.\n",
    "    y_validate: array-like, shape (n_samples,)\n",
    "        Target values for the validation samples.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    results: pandas DataFrame\n",
    "        Contains the train and validation accuracy for each value of k.\n",
    "    \"\"\"\n",
    "    # KNN model evaluation for different values of k\n",
    "    metrics = []\n",
    "    train_score = []\n",
    "    validate_score = []\n",
    "    for k in range(1, 21):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_bow, y_train)\n",
    "        train_score.append(knn.score(X_bow, y_train))\n",
    "        validate_score.append(knn.score(X_validate_bow, y_validate))\n",
    "        diff_score = train_score[-1] - validate_score[-1]\n",
    "        metrics.append({'k': k, 'train_score': train_score[-1], 'validate_score': validate_score[-1], 'diff_score': diff_score})\n",
    "\n",
    "    baseline_accuracy = (y_train == 6).mean()\n",
    "\n",
    "    results = pd.DataFrame.from_records(metrics)\n",
    "\n",
    "    # Plot results\n",
    "    # (visualization code here)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c50361-462a-441c-8c46-918f7314a771",
   "metadata": {},
   "source": [
    "### Question 2: Does the presence of specific libraries in the README file correspond with the programming language used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d74533e-499b-4aa8-ba04-9052cc690701",
   "metadata": {},
   "source": [
    "### Question 4: What are the least frequently used words throughout the dataset and for each language?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c850d6-57cb-4029-ad98-3c03e41989c5",
   "metadata": {},
   "source": [
    "### TRAIN SPLIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc09a80e-6539-4822-81d3-61404ab6b9b6",
   "metadata": {},
   "source": [
    "# EXPLORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcbc15e-1c5d-4f5d-8620-db59417596fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ee6850-1ddf-4812-a9a2-23271b3d7b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "se = pd.Series(cleaned_list)\n",
    "words_df['cleaned_text'] = se.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f006c344-471c-4c30-8d78-f2adf77d4f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86437100-006c-44de-a96f-61d5f2acf60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = split_data(df, 'language')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e44959f-f300-44b1-840f-32a07e955778",
   "metadata": {},
   "outputs": [],
   "source": [
    "    separate specific words by language category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a4d1af-f6b2-4e90-8b97-b3c2b1c54827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can do that process with a join on a Series and not just a list\n",
    "# we will do that all words and categories\n",
    "# we will pass our basic cleaning on top of that\n",
    "\n",
    "JavaScript_words = clean(' '.join(train[train.language=='JavaScript']['clean_contents']))\n",
    "Python_words = clean(' '.join(train[train.language=='Python']['clean_contents']))\n",
    "Java_words = clean(' '.join(train[train.language=='Java']['clean_contents']))\n",
    "TypeScript_words = clean(' '.join(train[train.language=='TypeScript']['clean_contents']))\n",
    "HTML_words = clean(' '.join(train[train.language=='HTML']['clean_contents']))\n",
    "Other_words = clean(' '.join(train[train.language=='Other']['clean_contents']))\n",
    "all_words = clean(' '.join(train['clean_contents']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
