{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fa9fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Optional, Union, cast\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "# from env_miatta import github_token, github_username\n",
    "import time\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "819f7f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JavaScript          31\n",
       "Python              15\n",
       "Java                11\n",
       "HTML                 7\n",
       "C                    6\n",
       "Jupyter Notebook     5\n",
       "Shell                5\n",
       "Ruby                 4\n",
       "C++                  3\n",
       "CSS                  3\n",
       "Go                   3\n",
       "TypeScript           3\n",
       "SCSS                 2\n",
       "PowerShell           1\n",
       "Kotlin               1\n",
       "Bicep                1\n",
       "HCL                  1\n",
       "Vim script           1\n",
       "Objective-C          1\n",
       "Vue                  1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aquire data using methods described above.\n",
    "words_df = pd.read_json('data2.json')\n",
    "words_df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18fb6f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenizes the words in the input string.\n",
    "    \"\"\"\n",
    "    tokenizer = ToktokTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def clean(text: str) -> list: \n",
    "    \"\"\"\n",
    "    Cleans up the input text data.\n",
    "    \"\"\"\n",
    "    text = (text.encode('ascii', 'ignore')\n",
    "                .decode('utf-8', 'ignore')\n",
    "                .lower())\n",
    "    \n",
    "    words = re.sub(r'[^\\w\\s]', ' ', text).split()\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    \n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]\n",
    "\n",
    "def nlp_wrangle():\n",
    "    \"\"\"\n",
    "    Performs data wrangling for natural language processing (NLP) tasks.\n",
    "    Returns a processed DataFrame for NLP analysis.\n",
    "    \"\"\"\n",
    "    # Load data from JSON file\n",
    "    df = pd.read_json('data2.json')\n",
    "    \n",
    "    # Tokenize and clean contents\n",
    "    df['clean_contents'] = df.readme_contents.apply(tokenize).apply(' '.join)\n",
    "    df['clean_contents'] = df.clean_contents.apply(clean).apply(' '.join)\n",
    "\n",
    "    # Words to remove\n",
    "    words_to_remove = [\"http\", \"com\", \"124\", \"www\", \"1\", \"github\", \"top\", \"go\", \"android\", \"content\", \"table\",\n",
    "                       \"107\", \"markdown\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"md\"]\n",
    "\n",
    "    # Remove specific words from clean_contents\n",
    "    for word in words_to_remove:\n",
    "        df['clean_contents'] = df['clean_contents'].str.replace(word, '')\n",
    "\n",
    "#     # Sentiment analysis\n",
    "#     sia = nltk.sentiment.SentimentIntensityAnalyzer()\n",
    "#     df['sentiment'] = df['clean_contents'].apply(lambda doc: sia.polarity_scores(doc)['compound'])\n",
    "\n",
    "    # Add message_length and word_count columns\n",
    "    df['message_length'] = df['clean_contents'].str.len()\n",
    "    df['word_count'] = df.clean_contents.apply(clean).apply(len)\n",
    "\n",
    "    # Keep only top languages and assign others to 'Other'\n",
    "    languages_to_keep = ['JavaScript', 'Python', 'Java', 'TypeScript', 'HTML']\n",
    "    df['language'] = np.where(df['language'].isin(languages_to_keep), df['language'], 'Other')\n",
    "\n",
    "    # Filter DataFrame based on conditions\n",
    "    df = df.loc[(df['word_count'] <= 10000) & (df['message_length'] <= 60000)]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8336f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df_w = nlp_wrangle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfdee624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>clean_contents</th>\n",
       "      <th>message_length</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheAlgorithms/Python</td>\n",
       "      <td>Python</td>\n",
       "      <td>&lt;div align=\"center\"&gt;\\n&lt;!-- Title: --&gt;\\n  &lt;a hr...</td>\n",
       "      <td>div align center title href    thealrithms img...</td>\n",
       "      <td>1801</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apache/flink</td>\n",
       "      <td>Java</td>\n",
       "      <td># Apache Flink\\n\\nApache Flink is an open sour...</td>\n",
       "      <td>apache flink apache flink open source stream p...</td>\n",
       "      <td>3271</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>forezp/SpringCloudLearning</td>\n",
       "      <td>Java</td>\n",
       "      <td>&gt;转载请标明出处： \\n&gt; http://blog.csdn.net/forezp/arti...</td>\n",
       "      <td>blog csdn net forezp article detail   blog cs...</td>\n",
       "      <td>4825</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>learn-co-students/python-dictionaries-readme-d...</td>\n",
       "      <td>Other</td>\n",
       "      <td>\\n# Dictionaries \\n\\n### Introduction\\n\\nAfter...</td>\n",
       "      <td>dictionary introduction introducing working li...</td>\n",
       "      <td>6115</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angular/angular-phonecat</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td># AngularJS Phone Catalog Tutorial Application...</td>\n",
       "      <td>angularjs phone catalog tutorial application o...</td>\n",
       "      <td>7533</td>\n",
       "      <td>1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>lin-xin/vue-manage-system</td>\n",
       "      <td>Other</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "      <td>payload allshortcutsenabled false filetree ite...</td>\n",
       "      <td>18414</td>\n",
       "      <td>2846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Significant-Gravitas/Auto-GPT</td>\n",
       "      <td>Python</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "      <td>payload allshortcutsenabled false filetree ite...</td>\n",
       "      <td>34078</td>\n",
       "      <td>5072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>namndwebdev/tang-crush</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "      <td>payload allshortcutsenabled false filetree ite...</td>\n",
       "      <td>6024</td>\n",
       "      <td>859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>learn-co-students/javascript-arrays-lab-bootca...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "      <td>payload allshortcutsenabled false filetree ite...</td>\n",
       "      <td>10055</td>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>learn-co-students/jupyter-notebook-introductio...</td>\n",
       "      <td>Other</td>\n",
       "      <td>{\"payload\":{\"allShortcutsEnabled\":false,\"fileT...</td>\n",
       "      <td>payload allshortcutsenabled false filetree ite...</td>\n",
       "      <td>17179</td>\n",
       "      <td>2371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  repo    language  \\\n",
       "0                                 TheAlgorithms/Python      Python   \n",
       "1                                         apache/flink        Java   \n",
       "2                           forezp/SpringCloudLearning        Java   \n",
       "3    learn-co-students/python-dictionaries-readme-d...       Other   \n",
       "4                             angular/angular-phonecat  JavaScript   \n",
       "..                                                 ...         ...   \n",
       "109                          lin-xin/vue-manage-system       Other   \n",
       "110                      Significant-Gravitas/Auto-GPT      Python   \n",
       "112                             namndwebdev/tang-crush  JavaScript   \n",
       "113  learn-co-students/javascript-arrays-lab-bootca...  JavaScript   \n",
       "115  learn-co-students/jupyter-notebook-introductio...       Other   \n",
       "\n",
       "                                       readme_contents  \\\n",
       "0    <div align=\"center\">\\n<!-- Title: -->\\n  <a hr...   \n",
       "1    # Apache Flink\\n\\nApache Flink is an open sour...   \n",
       "2    >转载请标明出处： \\n> http://blog.csdn.net/forezp/arti...   \n",
       "3    \\n# Dictionaries \\n\\n### Introduction\\n\\nAfter...   \n",
       "4    # AngularJS Phone Catalog Tutorial Application...   \n",
       "..                                                 ...   \n",
       "109  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...   \n",
       "110  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...   \n",
       "112  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...   \n",
       "113  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...   \n",
       "115  {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...   \n",
       "\n",
       "                                        clean_contents  message_length  \\\n",
       "0    div align center title href    thealrithms img...            1801   \n",
       "1    apache flink apache flink open source stream p...            3271   \n",
       "2     blog csdn net forezp article detail   blog cs...            4825   \n",
       "3    dictionary introduction introducing working li...            6115   \n",
       "4    angularjs phone catalog tutorial application o...            7533   \n",
       "..                                                 ...             ...   \n",
       "109  payload allshortcutsenabled false filetree ite...           18414   \n",
       "110  payload allshortcutsenabled false filetree ite...           34078   \n",
       "112  payload allshortcutsenabled false filetree ite...            6024   \n",
       "113  payload allshortcutsenabled false filetree ite...           10055   \n",
       "115  payload allshortcutsenabled false filetree ite...           17179   \n",
       "\n",
       "     word_count  \n",
       "0           284  \n",
       "1           463  \n",
       "2           635  \n",
       "3           850  \n",
       "4          1083  \n",
       "..          ...  \n",
       "109        2846  \n",
       "110        5072  \n",
       "112         859  \n",
       "113        1343  \n",
       "115        2371  \n",
       "\n",
       "[97 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d412fe07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{34,\n",
       " 39,\n",
       " 41,\n",
       " 42,\n",
       " 45,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 59,\n",
       " 69,\n",
       " 71,\n",
       " 78,\n",
       " 80,\n",
       " 86,\n",
       " 90,\n",
       " 92,\n",
       " 97,\n",
       " 111,\n",
       " 114,\n",
       " 116,\n",
       " 117}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= set(range(0,118)) - set(list(words_df_w.index))\n",
    "# a = list(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d2eaa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df_temp = words_df[words_df.index == 41]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7862ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41    {\"payload\":{\"allShortcutsEnabled\":false,\"fileT...\n",
       "Name: readme_contents, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df_temp.readme_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2997ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525dd999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7084e3db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9017a7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8baccb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d635c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dfc7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11031d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797c634e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b359f4db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501e0479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa593a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc7c8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c855c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b481840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_list = []\n",
    "\n",
    "def clean(text: str) -> list: \n",
    "    \"\"\"\n",
    "    Cleans up the input text data.\n",
    "    \"\"\"\n",
    "    text = (text.encode('ascii', 'ignore')\n",
    "                .decode('utf-8', 'ignore')\n",
    "                .lower())\n",
    "    \n",
    "    words = re.sub(r'[^\\w\\s]', ' ', text).split()\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    \n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]\n",
    "\n",
    "for content in words_df.readme_contents:\n",
    "    cleaned_text = clean(content)\n",
    "    cleaned_list.append(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad6319",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29b074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "se = pd.Series(cleaned_list)\n",
    "words_df['cleaned_text'] = se.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f3583",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a7040d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59031b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4fb08f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
